{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a39dfed5",
   "metadata": {},
   "source": [
    "1. **What is a Decision Tree, and how does it work in the context of classification?**\n",
    "\n",
    "\n",
    "**Decision Tree**\n",
    "\n",
    "- A Decision Tree is a supervised machine learning algorithm used for classification and regression.\n",
    "- In classification, it predicts a class label by learning simple decision rules from the data.\n",
    "\n",
    "**How It Works in Classification**\n",
    "\n",
    "- The algorithm splits the dataset into smaller subsets based on feature values.\n",
    "- At each step, it selects the feature that best separates the data into distinct classes.\n",
    "- Splitting continues until:\n",
    "  - all samples in a node belong to the same class, or\n",
    "  - stopping criteria like max depth or minimum samples per leaf are reached.\n",
    "\n",
    "**Structure**\n",
    "\n",
    "- **Root Node**: Represents the entire dataset and the first splitting feature.\n",
    "- **Internal Nodes**: Represent decision points based on feature values.\n",
    "- **Leaf Nodes**: Contain final class predictions.\n",
    "\n",
    "**Decision Rule**\n",
    "\n",
    "- At each node, the split is chosen using metrics such as:\n",
    "  - Gini Index\n",
    "  - Entropy (Information Gain)\n",
    "\n",
    "**Final Prediction**\n",
    "\n",
    "- A new sample is classified by traversing the tree from root to leaf, following decision rules at each node, resulting in a class label.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623a081c",
   "metadata": {},
   "source": [
    "2. **Explain the concepts of Gini Impurity and Entropy as impurity measures. How do they impact the splits in a Decision Tree?**\n",
    "\n",
    "\n",
    "**Gini Impurity**\n",
    "\n",
    "- Gini Impurity measures how often a randomly chosen sample would be incorrectly classified if it was randomly labeled according to the class distribution in a node.\n",
    "- Formula: Gini = 1 − Σ (pᵢ)²  \n",
    "  where pᵢ is the proportion of samples belonging to class i.\n",
    "- Lower Gini indicates a purer node (more samples from a single class).\n",
    "\n",
    "**Entropy**\n",
    "\n",
    "- Entropy measures the amount of uncertainty or disorder in a node.\n",
    "- Formula: Entropy = − Σ (pᵢ * log₂(pᵢ))  \n",
    "  where pᵢ is the proportion of samples belonging to class i.\n",
    "- Lower entropy means higher purity.\n",
    "\n",
    "**Impact on Decision Tree Splitting**\n",
    "\n",
    "- Both Gini and Entropy evaluate how well a feature split separates the data into pure groups.\n",
    "- During tree building:\n",
    "  - The algorithm tries all possible splits.\n",
    "  - It chooses the split that results in the **largest reduction in impurity** (highest Information Gain for entropy or highest Gini reduction).\n",
    "- The goal is to create nodes that contain samples mostly from a single class, improving classification accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96b5357",
   "metadata": {},
   "source": [
    "3. **What is the difference between Pre-Pruning and Post-Pruning in Decision Trees? Give one practical advantage of using each.**\n",
    "\n",
    "**Pre-Pruning**\n",
    "\n",
    "- Pre-pruning (also called early stopping) stops the tree from growing too deep during training.\n",
    "- Conditions like maximum depth, minimum samples per split, or minimum information gain are applied to halt further splits.\n",
    "\n",
    "**Practical Advantage of Pre-Pruning**\n",
    "\n",
    "- Reduces training time and prevents the tree from becoming overly complex, helping to avoid overfitting early.\n",
    "\n",
    "**Post-Pruning**\n",
    "\n",
    "- Post-pruning allows the tree to grow fully first and then removes branches that do not provide meaningful improvement.\n",
    "- Nodes or subtrees are pruned based on validation performance or pruning cost complexity (such as reduced error pruning).\n",
    "\n",
    "**Practical Advantage of Post-Pruning**\n",
    "\n",
    "- Produces simpler and more generalizable trees because pruning decisions are based on observed performance rather than assumptions during training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a258dc",
   "metadata": {},
   "source": [
    "4. **What is Information Gain in Decision Trees, and why is it important for choosing the best split?**\n",
    "\n",
    "**Information Gain**\n",
    "\n",
    "- Information Gain measures how much uncertainty (impurity) is reduced in the target variable after splitting the dataset based on a feature.\n",
    "- It is calculated as the difference between the entropy of the parent node and the weighted entropy of the child nodes after the split.\n",
    "\n",
    "**Formula**\n",
    "\n",
    "  Information Gain = Entropy(parent) − Σ ( (nᵢ / N) × Entropy(childᵢ) )\n",
    "\n",
    "  nᵢ = number of samples in child node  \n",
    "  N = total samples in parent node\n",
    "\n",
    "**Why It Is Important for Choosing the Best Split**\n",
    "\n",
    "- Information Gain identifies which feature provides the most effective separation of classes at each step.\n",
    "- A higher Information Gain means the split leads to purer child nodes.\n",
    "- Decision Trees aim to reduce impurity with every split, so the feature with the highest Information Gain is chosen.\n",
    "- This leads to better classification accuracy and a more meaningful tree structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d18b41",
   "metadata": {},
   "source": [
    "5. **What are some common real-world applications of Decision Trees, and what are their main advantages and limitations?**\n",
    "\n",
    "**Real-World Applications of Decision Trees**\n",
    "\n",
    "- **Fraud detection** in banking and financial institutions.\n",
    "- **Medical diagnosis** for predicting disease likelihood.\n",
    "- **Customer churn prediction** in telecom and subscription services.\n",
    "- **Loan approval** and credit risk assessment.\n",
    "- **Product recommendation** and customer segmentation in e-commerce.\n",
    "- **Weather prediction** and agriculture planning.\n",
    "\n",
    "---\n",
    "\n",
    "**Advantages**\n",
    "\n",
    "- **Easy to understand and interpret** because decisions are shown in a tree-like structure.\n",
    "- **Requires little data preprocessing** (no scaling or normalization needed).\n",
    "- **Can handle both numerical and categorical variables.**\n",
    "- **Captures non-linear relationships** between features and target.\n",
    "\n",
    "---\n",
    "\n",
    "**Limitations**\n",
    "\n",
    "- **Prone to overfitting** when the tree grows too deep.\n",
    "- **Small changes in data can drastically alter the tree structure**, reducing stability.\n",
    "- **Biased toward features with many possible split values**, unless corrected.\n",
    "- **Less suitable for continuous prediction tasks compared to ensemble models.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fd20e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree Classifier: 1.0\n",
      "Feature Importances: [0.         0.01667014 0.90614339 0.07718647]\n",
      "Feature Names and Importance:\n",
      "sepal length (cm): 0.0\n",
      "sepal width (cm): 0.016670139612419255\n",
      "petal length (cm): 0.9061433868879218\n",
      "petal width (cm): 0.07718647349965893\n"
     ]
    }
   ],
   "source": [
    "# 6. Write a Python program to:\n",
    "# ● Load the Iris Dataset\n",
    "# ● Train a Decision Tree Classifier using the Gini criterion\n",
    "# ● Print the model’s accuracy and feature importances\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Load Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Train–test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Train Decision Tree Classifier using Gini criterion\n",
    "model = DecisionTreeClassifier(criterion='gini', random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and calculate accuracy\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"Accuracy of Decision Tree Classifier:\", accuracy)\n",
    "print(\"Feature Importances:\", model.feature_importances_)\n",
    "print(\"Feature Names and Importance:\")\n",
    "for name, score in zip(iris.feature_names, model.feature_importances_):\n",
    "    print(f\"{name}: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96990e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Fully-Grown Tree: 1.0\n",
      "Accuracy of Tree with max_depth=3: 1.0\n"
     ]
    }
   ],
   "source": [
    "# 7. Write a Python program to:\n",
    "# ● Load the Iris Dataset\n",
    "# ● Train a Decision Tree Classifier with max_depth=3 and compare its accuracy to a fully-grown tree.\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Train–test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Fully grown decision tree\n",
    "full_tree = DecisionTreeClassifier(random_state=42)\n",
    "full_tree.fit(X_train, y_train)\n",
    "full_pred = full_tree.predict(X_test)\n",
    "full_accuracy = accuracy_score(y_test, full_pred)\n",
    "\n",
    "# Decision tree with max_depth=3\n",
    "pruned_tree = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "pruned_tree.fit(X_train, y_train)\n",
    "pruned_pred = pruned_tree.predict(X_test)\n",
    "pruned_accuracy = accuracy_score(y_test, pruned_pred)\n",
    "\n",
    "# Print accuracy comparison\n",
    "print(\"Accuracy of Fully-Grown Tree:\", full_accuracy)\n",
    "print(\"Accuracy of Tree with max_depth=3:\", pruned_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8540014b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 10.416078431372549\n",
      "\n",
      "Feature Importances:\n",
      "CRIM: 0.0513\n",
      "ZN: 0.0034\n",
      "INDUS: 0.0058\n",
      "CHAS: 0.0000\n",
      "NOX: 0.0271\n",
      "RM: 0.6003\n",
      "AGE: 0.0136\n",
      "DIS: 0.0707\n",
      "RAD: 0.0019\n",
      "TAX: 0.0125\n",
      "PTRATIO: 0.0110\n",
      "B: 0.0090\n",
      "LSTAT: 0.1933\n"
     ]
    }
   ],
   "source": [
    "# 8. Write a Python program to:\n",
    "# ● Load the Boston Housing Dataset\n",
    "# ● Train a Decision Tree Regressor\n",
    "# ● Print the Mean Squared Error (MSE) and feature importances\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load Boston Housing dataset from OpenML\n",
    "data = fetch_openml(name=\"boston\", version=1, as_frame=True)\n",
    "X = data.data\n",
    "y = data.target\n",
    "feature_names = X.columns\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Train Decision Tree Regressor\n",
    "model = DecisionTreeRegressor(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Compute MSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Display results\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"\\nFeature Importances:\")\n",
    "for name, importance in zip(feature_names, model.feature_importances_):\n",
    "    print(f\"{name}: {importance:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21c5e844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 4, 'min_samples_split': 2}\n",
      "Model Accuracy with Best Parameters: 1.0\n"
     ]
    }
   ],
   "source": [
    "# 9. Write a Python program to:\n",
    "# ● Load the Iris Dataset\n",
    "# ● Tune the Decision Tree’s max_depth and min_samples_split using\n",
    "# GridSearchCV\n",
    "# ● Print the best parameters and the resulting model accuracy\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load Iris Dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Parameter grid for tuning\n",
    "param_grid = {\n",
    "    \"max_depth\": [1, 2, 3, 4, 5, None],\n",
    "    \"min_samples_split\": [2, 3, 4, 5, 6]\n",
    "}\n",
    "\n",
    "# Decision Tree Classifier with GridSearchCV\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=dt,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Evaluate on test set\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Model Accuracy with Best Parameters:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00397a89",
   "metadata": {},
   "source": [
    "10. **Imagine you’re working as a data scientist for a healthcare company that wants to predict whether a patient has a certain disease. You have a large dataset with mixed data types and some missing values. Explain the step-by-step process you would follow to:**\n",
    "- ● Handle the missing values\n",
    "- ● Encode the categorical features\n",
    "- ● Train a Decision Tree model\n",
    "- ● Tune its hyperparameters\n",
    "- ● Evaluate its performance\n",
    "And describe what business value this model could provide in the real-worldsetting.\n",
    "\n",
    "**Overall approach (high-level)**\n",
    "\n",
    "- **Goal:** build a robust, explainable Decision Tree classifier to predict disease presence from mixed-type healthcare data, while handling missing values and avoiding leakage.\n",
    "- **Key principles:** preserve clinical meaning, avoid leakage, handle class imbalance, prefer interpretability and calibration, monitor post-deployment.\n",
    "\n",
    "**1) Handle missing values**\n",
    "\n",
    "- **Understand missingness**\n",
    "  - Determine mechanism: Missing Completely at Random (MCAR), Missing at Random (MAR), Missing Not at Random (MNAR).\n",
    "  - Check missing-rate per feature and by class (target).\n",
    "- **Simple strategies**\n",
    "  - **Numerical:** median imputation (robust) or mean if symmetric; consider KNN or IterativeImputer for complex patterns.\n",
    "  - **Categorical:** impute with a special category like `\"Missing\"` or the mode.\n",
    "- **Advanced strategies**\n",
    "  - **Model-based imputation:** Iterative (multivariate) imputer or predictive models if missingness is informative.\n",
    "  - **Missingness indicator:** create a binary flag `feature_missing` for features with >~1% missing to capture MNAR signals.\n",
    "- **Practical rules**\n",
    "  - Never impute based on target or test set statistics during training (avoid leakage).\n",
    "  - Impute using training set statistics and apply same transformers to validation/test.\n",
    "  - Prefer simple, interpretable imputations in healthcare; preserve original distribution if possible.\n",
    "\n",
    "**2) Encode categorical features**\n",
    "\n",
    "- **Separate types**\n",
    "  - **Nominal (no order):** use One-Hot Encoding or low-cardinality target encoding.\n",
    "  - **Ordinal (known order):** use OrdinalEncoder with a clinically meaningful mapping.\n",
    "  - **High-cardinality (>20–50 categories):** consider target/mean encoding, frequency encoding, or embedding techniques; apply smoothing and cross-validation to prevent leakage.\n",
    "- **Avoid leakage with target encoding**\n",
    "  - Use K-fold target encoding or implement target encoding inside cross-validation folds / training pipeline.\n",
    "- **Tree-specific notes**\n",
    "  - Decision trees do not require scaling.\n",
    "  - Trees handle integer-encoded categories, but consistent encoding is essential.\n",
    "- **Pipeline usage**\n",
    "  - Use `ColumnTransformer` to apply different encoders per column so transformations are reproducible.\n",
    "\n",
    "**3) Train a Decision Tree model**\n",
    "\n",
    "- **Data split**\n",
    "  - Create stratified train/validation/test splits (e.g., 60/20/20) to preserve class ratios.\n",
    "- **Baseline model**\n",
    "  - Train a simple `DecisionTreeClassifier(random_state=R)` with default parameters to establish baseline metrics.\n",
    "- **Preprocessing pipeline**\n",
    "  - Build a scikit-learn `Pipeline` or `ColumnTransformer` that:\n",
    "    - imputes numericals and categoricals,\n",
    "    - applies encoders,\n",
    "    - optionally creates missingness indicators and basic interactions,\n",
    "    - then fits the `DecisionTreeClassifier`.\n",
    "- **Class imbalance**\n",
    "  - If disease is rare, use `class_weight='balanced'`, oversampling (SMOTE) inside cross-validation, or use thresholding based on business costs.\n",
    "\n",
    "**4) Tune hyperparameters**\n",
    "\n",
    "- **Important hyperparameters to consider**\n",
    "  - `max_depth` — controls complexity and overfitting.\n",
    "  - `min_samples_split` / `min_samples_leaf` — avoid tiny leaves.\n",
    "  - `max_features` — number of features to consider at each split.\n",
    "  - `criterion` — 'gini' or 'entropy'.\n",
    "  - `class_weight` — handle imbalance.\n",
    "  - `ccp_alpha` — cost-complexity pruning parameter.\n",
    "- **Search strategy**\n",
    "  - Use `GridSearchCV` or `RandomizedSearchCV` with `StratifiedKFold` CV.\n",
    "  - Score using metrics relevant to business (see evaluation below), not just accuracy.\n",
    "  - Use nested CV for unbiased estimation when tuning and reporting final performance.\n",
    "- **Computational tips**\n",
    "  - Start with wide `RandomizedSearchCV`, then refine with `GridSearchCV`.\n",
    "  - Limit tree depth early to avoid extremely large trees.\n",
    "\n",
    "**5) Evaluate performance**\n",
    "\n",
    "- **Evaluation splits**\n",
    "  - Hold out a final test set not used during training or tuning.\n",
    "- **Metrics (choose by business needs)**\n",
    "  - **Primary:** ROC-AUC (general separability), PR-AUC (for imbalanced data), or F1 if balancing precision/recall.\n",
    "  - **Clinical emphasis:** sensitivity (recall) to catch disease cases, specificity to avoid false alarms — choose threshold accordingly.\n",
    "  - **Other:** Accuracy (useful if classes balanced), Precision, Recall, F1-score, Confusion Matrix.\n",
    "  - **Calibration:** use calibration curve / Brier score — well-calibrated probabilities are critical in healthcare.\n",
    "- **Explainability & validation**\n",
    "  - Compute feature importances; use SHAP/LIME to explain individual predictions and validate clinical plausibility.\n",
    "  - Check partial dependence plots for how features affect risk.\n",
    "- **Residual / error analysis**\n",
    "  - Examine false negatives and false positives for systematic patterns (age groups, missing data, subpopulations).\n",
    "- **Robustness & stability**\n",
    "  - Test model on subgroups (age, gender, hospital) to detect bias.\n",
    "  - Perform sensitivity analyses (imputation methods, encoding variants).\n",
    "- **Operational metrics**\n",
    "  - Decision-curve analysis or cost-benefit analysis to quantify clinical utility given downstream costs (tests, treatments, missed cases).\n",
    "\n",
    "**6) Deployment & monitoring (brief)**\n",
    "\n",
    "- **Model packaging**\n",
    "  - Serialize pipeline (`joblib`) that includes imputer, encoder, and tree.\n",
    "- **Monitoring**\n",
    "  - Track data drift, model performance drift, and calibration over time.\n",
    "  - Re-evaluate and retrain periodically as new labeled data arrives.\n",
    "- **Governance**\n",
    "  - Maintain audit trail, clinician review, and documentation of feature transformations and limitations.\n",
    "\n",
    "**7) Business value of the model**\n",
    "\n",
    "- **Early detection & intervention**\n",
    "  - Identify high-risk patients earlier so clinicians can run confirmatory tests or start preventive care.\n",
    "- **Resource allocation**\n",
    "  - Prioritize limited diagnostic resources (imaging, specialist appointments) for likely positives.\n",
    "- **Cost reduction**\n",
    "  - Reduce unnecessary testing for low-risk patients and avoid expensive late-stage treatments via early action.\n",
    "- **Operational efficiency**\n",
    "  - Automate triage and flagging in electronic health records to streamline workflows.\n",
    "- **Clinical decision support**\n",
    "  - Provide transparent risk scores and feature-based explanations to assist clinician judgement.\n",
    "- **Population health**\n",
    "  - Inform screening programs and public-health interventions by identifying high-risk cohorts.\n",
    "- **Caveats**\n",
    "  - Must ensure model fairness, transparency, and clinical validation before live use; false negatives in healthcare can have serious consequences so align threshold and operating point with clinical risk tolerance.\n",
    "\n",
    "**8) Final recommendations**\n",
    "- In healthcare, prioritize explainability, calibration, and conservative thresholds for clinical safety.\n",
    "- Involve clinicians early for feature selection and to validate model outputs.\n",
    "- Maintain continuous monitoring and a retraining plan as the data distribution evolves.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657d3671",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
