{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNEGc6JBYqdX6AmKqQot3cq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Supervised Learning: Regression odels and Performance Metrics"],"metadata":{"id":"_XhgBpvVd5nr"}},{"cell_type":"markdown","source":["1. **What is Simple Linear Regression (SLR)? Explain its purpose.**\n","\n","**Simple Linear Regression (SLR)**\n","\n","- Simple Linear Regression is a statistical technique used to model the relationship between one independent variable (X) and one dependent variable (Y).\n","- It fits a straight line that best explains how changes in X affect Y.\n","- The model is represented as:\n","  \n","  Y = β₀ + β₁X + ε\n","\n","  **β₀** is the intercept, **β₁** is the slope, and **ε** is the error term.\n","\n","**Purpose**\n","\n","- To predict the value of Y based on a given value of X.\n","- To understand the strength and direction of the relationship between X and Y.\n","- To analyze trends and make data-driven decisions using a simple linear pattern."],"metadata":{"id":"DrNHTdOaeSmd"}},{"cell_type":"markdown","source":["2. **What are the key assumptions of Simple Linear Regression?**\n","\n","**Key Assumptions of Simple Linear Regression**\n","\n","- **Linearity**  \n","  The relationship between the independent variable (X) and dependent variable (Y) must be linear.\n","\n","- **Independence of Errors**  \n","  Residuals (errors) should be independent of each other.\n","\n","- **Homoscedasticity**  \n","  The variance of residuals should remain constant across all values of X.\n","\n","- **Normality of Residuals**  \n","  Residuals should follow a roughly normal distribution.\n","\n","- **No Autocorrelation**  \n","  Residuals should not show patterns over time, especially in time-series data.\n","\n","- **No Multicollinearity**  \n","  Automatically satisfied because SLR uses only one independent variable.\n"],"metadata":{"id":"qk8ipwPvemlN"}},{"cell_type":"markdown","source":["3. **Write the mathematical equation for a simple linear regression model and explain each term.**\n","\n","**Simple Linear Regression Equation**\n","\n","  Y = β₀ + β₁X + ε\n","\n","**Explanation of Each Term**\n","\n","- **Y**  \n","  The dependent variable (the value we want to predict).\n","\n","- **X**  \n","  The independent variable (the predictor).\n","\n","- **β₀ (Intercept)**  \n","  The value of Y when X = 0. It represents the starting point of the line.\n","\n","- **β₁ (Slope)**  \n","  The amount by which Y changes for each one-unit increase in X.\n","\n","- **ε (Error Term)**  \n","  The difference between the actual value and the predicted value.  \n","  It captures randomness, noise, or factors not included in the model.\n"],"metadata":{"id":"qvniyossewKk"}},{"cell_type":"markdown","source":["4. **Provide a real-world example where simple linear regression can be applied.**\n","\n","**Real-World Example of Simple Linear Regression**\n","\n","- A company wants to predict **monthly sales revenue** based on **advertising spend**.\n","- Here, advertising spend (X) is the independent variable, and sales revenue (Y) is the dependent variable.\n","- By fitting a simple linear regression model, the company can estimate how much revenue increases for every extra unit of money spent on advertising.\n","- This helps in forecasting future sales and making budgeting decisions.\n"],"metadata":{"id":"ZfF9UshCfBCU"}},{"cell_type":"markdown","source":["5. **What is the method of least squares in linear regression?**\n","\n","**Method of Least Squares**\n","\n","- The method of least squares is a technique used to find the best-fitting regression line for a set of data points.\n","- It works by minimizing the **sum of the squared differences** between the actual values (Y) and the predicted values (Ŷ) from the regression line.\n","\n","**How It Works**\n","\n","- For each data point, calculate the residual:  \n","  residual = (Y − Ŷ)\n","- Square each residual to avoid negative values.\n","- Add all squared residuals together.\n","- The regression algorithm chooses the line for which this total squared error is the smallest.\n","\n","**Purpose**\n","\n","- Ensures the line fits the data as closely as possible.\n","- Produces the most accurate estimates of the intercept and slope of the regression line.\n"],"metadata":{"id":"u0IyGVQdfOO0"}},{"cell_type":"markdown","source":["6. **What is Logistic Regression? How does it differ from Linear Regression?**\n","\n","**Logistic Regression**\n","\n","- Logistic Regression is a statistical model used for **classification tasks**, where the target variable is categorical (such as 0/1, Yes/No, Spam/Not Spam).\n","- Instead of predicting a continuous value, it predicts the **probability** that an input belongs to a particular class.\n","- It uses the **sigmoid (logistic) function** to convert linear combinations of inputs into probabilities between 0 and 1.\n","\n","**Key Equation**\n","\n","  p = 1 / (1 + e^-(β₀ + β₁X))\n","\n","  Where p is the probability of the positive class.\n","\n","**Difference from Linear Regression**\n","\n","- **Purpose**  \n","  - Linear Regression predicts continuous values.  \n","  - Logistic Regression predicts probabilities and class labels.\n","\n","- **Output Range**  \n","  - Linear Regression outputs any real number.  \n","  - Logistic Regression outputs values between 0 and 1.\n","\n","- **Model Type**  \n","  - Linear Regression fits a straight line.  \n","  - Logistic Regression fits an S-shaped curve using the sigmoid function.\n","\n","- **Loss Function**  \n","  - Linear Regression uses Mean Squared Error (MSE).  \n","  - Logistic Regression uses Log Loss (Binary Cross-Entropy).\n","\n","- **Applications**  \n","  - Linear Regression: predicting house prices, sales, etc.  \n","  - Logistic Regression: predicting fraud, disease diagnosis, email spam detection.\n"],"metadata":{"id":"hyzDQm54fYf-"}},{"cell_type":"markdown","source":["7. **Name and briefly describe three common evaluation metrics for regression models.**\n","\n","**Mean Absolute Error (MAE)**  \n","- Measures the average absolute difference between actual and predicted values.  \n","- Lower MAE indicates better model performance.\n","\n","**Mean Squared Error (MSE)**  \n","- Calculates the average of squared differences between actual and predicted values.  \n","- Penalizes larger errors more heavily due to squaring.\n","\n","**R-squared (Coefficient of Determination)**  \n","- Represents how much of the variance in the dependent variable is explained by the model.  \n","- Ranges from 0 to 1, with higher values indicating a better fit."],"metadata":{"id":"FqUcPsijfl81"}},{"cell_type":"markdown","source":["8. **What is the purpose of the R-squared metric in regression analysis?**\n","\n","**Purpose of R-squared in Regression**\n","\n","- R-squared measures the proportion of the variance in the dependent variable (Y) that is explained by the independent variable(s) in the model.\n","- It indicates how well the regression line fits the data.\n","- The value ranges from 0 to 1:\n","  - 0 means the model explains none of the variation.\n","  - 1 means the model explains all of the variation.\n","- It helps determine the strength of the linear relationship and the overall goodness of fit of the model.\n"],"metadata":{"id":"I6_t9qjdf12b"}},{"cell_type":"code","source":["# 9. Write Python code to fit a simple linear regression model using scikit-learn and print the slope and intercept.\n","from sklearn.linear_model import LinearRegression\n","import numpy as np\n","\n","# Sample data\n","X = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)\n","Y = np.array([3, 4, 2, 5, 6])\n","\n","# Create and fit the model\n","model = LinearRegression()\n","model.fit(X, Y)\n","\n","# Print slope and intercept\n","print(\"Slope (β₁):\", model.coef_[0])\n","print(\"Intercept (β₀):\", model.intercept_)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NMISBKy9gYDa","executionInfo":{"status":"ok","timestamp":1763092598564,"user_tz":-330,"elapsed":2488,"user":{"displayName":"shivam singh","userId":"13846532010104603200"}},"outputId":"a82bf112-dc16-457f-d0c1-e2314661924a"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Slope (β₁): 0.6999999999999998\n","Intercept (β₀): 1.9000000000000004\n"]}]},{"cell_type":"markdown","source":["10. **How do you interpret the coefficients in a simple linear regression model?**\n","\n","**Interpreting Coefficients in Simple Linear Regression**\n","\n","- **Intercept (β₀)**  \n","  Represents the predicted value of Y when X = 0.  \n","  It shows the baseline level of the dependent variable.\n","\n","- **Slope (β₁)**  \n","  Indicates the change in Y for a one-unit increase in X.  \n","  - If β₁ is positive: Y increases as X increases.  \n","  - If β₁ is negative: Y decreases as X increases.  \n","  - The magnitude of β₁ shows how strongly X influences Y.\n","\n","- Overall, the coefficients describe how the independent variable impacts the dependent variable in a linear manner."],"metadata":{"id":"0tlyhh7dgGAM"}}]}